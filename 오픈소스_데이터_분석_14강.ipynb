{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mors119/Data-Analysis-with-Open-Source/blob/main/%EC%98%A4%ED%94%88%EC%86%8C%EC%8A%A4_%EB%8D%B0%EC%9D%B4%ED%84%B0_%EB%B6%84%EC%84%9D_14%EA%B0%95.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 14강 비정형 데이터 분석 : 패션 사진 데이터 활용\n",
        "\n",
        "### 목표\n",
        "\n",
        "- 비정형 데이터를 인공지능 모델로 분석하여 실무에서 활용 가능한 보고서 형태로 가공\n",
        "\n",
        "- 패션 트렌드라는 구체적인 주제를 통해, 비정형 데이터 분석의 실질적인 활용 방안을 경험하고자 함\n",
        "\n",
        "\n",
        "### 분석 프로세스 개요\n",
        "\n",
        "1. 데이터 수집\n",
        "  - requests를 이용한 RSS 데이터 수집\n",
        "  - lxml을 이용한 XML 파싱\n",
        "  - 이미지 데이터 추출\n",
        "2. VLM을 이용한 이미지 분석\n",
        "  - 프롬프트를 이용한 이미지 필터링\n",
        "  - 프롬프트를 이용한 스타일 분석\n",
        "3. LLM을 이용한 키워드 분석 및 보고서 작성\n",
        "  - 텍스트 전처리\n",
        "  - 색상 및 스타일 키워드 추출\n",
        "  - 워드 클라우드 분석\n",
        "  - 보고서 작성\n",
        "\n",
        "# 주의 : 런타임 GPU 로 설정 필요"
      ],
      "metadata": {
        "id": "xFHAUHwUwqEy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 4bit VLM 처리를 위한 bitsandbytes 설치\n",
        "# LLM 처리를 위한 VLLM 설치 (오래걸리는 작업(>5분)이므로 미리 실행!)\n",
        "!pip install bitsandbytes==0.45.3 vllm==0.7.3 transformers==4.48.2\n",
        "# 필요 시 세션 재시작"
      ],
      "metadata": {
        "id": "oRFE0WufwtWm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6e5e4dbf-e408-4609-963e-cc392ba3e73b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting bitsandbytes==0.45.3\n",
            "  Downloading bitsandbytes-0.45.3-py3-none-manylinux_2_24_x86_64.whl.metadata (5.0 kB)\n",
            "Collecting vllm==0.7.3\n",
            "  Downloading vllm-0.7.3-cp38-abi3-manylinux1_x86_64.whl.metadata (25 kB)\n",
            "Collecting transformers==4.48.2\n",
            "  Downloading transformers-4.48.2-py3-none-any.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch<3,>=2.0 in /usr/local/lib/python3.12/dist-packages (from bitsandbytes==0.45.3) (2.8.0+cu126)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from bitsandbytes==0.45.3) (2.0.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from vllm==0.7.3) (5.9.5)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (from vllm==0.7.3) (0.2.1)\n",
            "Collecting numpy>=1.17 (from bitsandbytes==0.45.3)\n",
            "  Downloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numba==0.60.0 in /usr/local/lib/python3.12/dist-packages (from vllm==0.7.3) (0.60.0)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.12/dist-packages (from vllm==0.7.3) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from vllm==0.7.3) (4.67.1)\n",
            "Collecting blake3 (from vllm==0.7.3)\n",
            "  Downloading blake3-1.0.7-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (217 bytes)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.12/dist-packages (from vllm==0.7.3) (9.0.0)\n",
            "Requirement already satisfied: tokenizers>=0.19.1 in /usr/local/lib/python3.12/dist-packages (from vllm==0.7.3) (0.22.1)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from vllm==0.7.3) (5.29.5)\n",
            "Requirement already satisfied: fastapi!=0.113.*,!=0.114.0,>=0.107.0 in /usr/local/lib/python3.12/dist-packages (from fastapi[standard]!=0.113.*,!=0.114.0,>=0.107.0; python_version >= \"3.9\"->vllm==0.7.3) (0.118.2)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from vllm==0.7.3) (3.13.0)\n",
            "Requirement already satisfied: openai>=1.52.0 in /usr/local/lib/python3.12/dist-packages (from vllm==0.7.3) (1.109.1)\n",
            "Requirement already satisfied: pydantic>=2.9 in /usr/local/lib/python3.12/dist-packages (from vllm==0.7.3) (2.11.10)\n",
            "Requirement already satisfied: prometheus_client>=0.18.0 in /usr/local/lib/python3.12/dist-packages (from vllm==0.7.3) (0.23.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (from vllm==0.7.3) (11.3.0)\n",
            "Collecting prometheus-fastapi-instrumentator>=7.0.0 (from vllm==0.7.3)\n",
            "  Downloading prometheus_fastapi_instrumentator-7.1.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: tiktoken>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from vllm==0.7.3) (0.12.0)\n",
            "Collecting lm-format-enforcer<0.11,>=0.10.9 (from vllm==0.7.3)\n",
            "  Downloading lm_format_enforcer-0.10.12-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting outlines==0.1.11 (from vllm==0.7.3)\n",
            "  Downloading outlines-0.1.11-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting lark==1.2.2 (from vllm==0.7.3)\n",
            "  Downloading lark-1.2.2-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting xgrammar==0.1.11 (from vllm==0.7.3)\n",
            "  Downloading xgrammar-0.1.11-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: typing_extensions>=4.10 in /usr/local/lib/python3.12/dist-packages (from vllm==0.7.3) (4.15.0)\n",
            "Requirement already satisfied: filelock>=3.16.1 in /usr/local/lib/python3.12/dist-packages (from vllm==0.7.3) (3.20.0)\n",
            "Collecting partial-json-parser (from vllm==0.7.3)\n",
            "  Downloading partial_json_parser-0.2.1.1.post6-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: pyzmq in /usr/local/lib/python3.12/dist-packages (from vllm==0.7.3) (26.2.1)\n",
            "Collecting msgspec (from vllm==0.7.3)\n",
            "  Downloading msgspec-0.19.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\n",
            "Collecting gguf==0.10.0 (from vllm==0.7.3)\n",
            "  Downloading gguf-0.10.0-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: importlib_metadata in /usr/local/lib/python3.12/dist-packages (from vllm==0.7.3) (8.7.0)\n",
            "Collecting mistral_common>=1.5.0 (from mistral_common[opencv]>=1.5.0->vllm==0.7.3)\n",
            "  Downloading mistral_common-1.8.5-py3-none-any.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from vllm==0.7.3) (6.0.3)\n",
            "Requirement already satisfied: six>=1.16.0 in /usr/local/lib/python3.12/dist-packages (from vllm==0.7.3) (1.17.0)\n",
            "Requirement already satisfied: setuptools>=74.1.1 in /usr/local/lib/python3.12/dist-packages (from vllm==0.7.3) (75.2.0)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.12/dist-packages (from vllm==0.7.3) (0.8.1)\n",
            "Collecting compressed-tensors==0.9.1 (from vllm==0.7.3)\n",
            "  Downloading compressed_tensors-0.9.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting depyf==0.18.0 (from vllm==0.7.3)\n",
            "  Downloading depyf-0.18.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.12/dist-packages (from vllm==0.7.3) (3.1.1)\n",
            "Collecting ray==2.40.0 (from ray[adag]==2.40.0->vllm==0.7.3)\n",
            "  Downloading ray-2.40.0-cp312-cp312-manylinux2014_x86_64.whl.metadata (17 kB)\n",
            "Collecting torch<3,>=2.0 (from bitsandbytes==0.45.3)\n",
            "  Downloading torch-2.5.1-cp312-cp312-manylinux1_x86_64.whl.metadata (28 kB)\n",
            "Collecting torchaudio==2.5.1 (from vllm==0.7.3)\n",
            "  Downloading torchaudio-2.5.1-cp312-cp312-manylinux1_x86_64.whl.metadata (6.4 kB)\n",
            "Collecting torchvision==0.20.1 (from vllm==0.7.3)\n",
            "  Downloading torchvision-0.20.1-cp312-cp312-manylinux1_x86_64.whl.metadata (6.1 kB)\n",
            "Collecting xformers==0.0.28.post3 (from vllm==0.7.3)\n",
            "  Downloading xformers-0.0.28.post3-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (1.0 kB)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.12/dist-packages (from transformers==4.48.2) (0.35.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers==4.48.2) (25.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers==4.48.2) (2024.11.6)\n",
            "Collecting tokenizers>=0.19.1 (from vllm==0.7.3)\n",
            "  Downloading tokenizers-0.21.4-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.12/dist-packages (from transformers==4.48.2) (0.6.2)\n",
            "Collecting astor (from depyf==0.18.0->vllm==0.7.3)\n",
            "  Downloading astor-0.8.1-py2.py3-none-any.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.12/dist-packages (from depyf==0.18.0->vllm==0.7.3) (0.3.8)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba==0.60.0->vllm==0.7.3) (0.43.0)\n",
            "Collecting interegular (from outlines==0.1.11->vllm==0.7.3)\n",
            "  Downloading interegular-0.3.3-py37-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from outlines==0.1.11->vllm==0.7.3) (3.1.6)\n",
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.12/dist-packages (from outlines==0.1.11->vllm==0.7.3) (1.6.0)\n",
            "Collecting diskcache (from outlines==0.1.11->vllm==0.7.3)\n",
            "  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: referencing in /usr/local/lib/python3.12/dist-packages (from outlines==0.1.11->vllm==0.7.3) (0.36.2)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.12/dist-packages (from outlines==0.1.11->vllm==0.7.3) (4.25.1)\n",
            "Collecting pycountry (from outlines==0.1.11->vllm==0.7.3)\n",
            "  Downloading pycountry-24.6.1-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting airportsdata (from outlines==0.1.11->vllm==0.7.3)\n",
            "  Downloading airportsdata-20250909-py3-none-any.whl.metadata (9.2 kB)\n",
            "Collecting outlines_core==0.1.26 (from outlines==0.1.11->vllm==0.7.3)\n",
            "  Downloading outlines_core-0.1.26-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.12/dist-packages (from ray==2.40.0->ray[adag]==2.40.0->vllm==0.7.3) (8.3.0)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from ray==2.40.0->ray[adag]==2.40.0->vllm==0.7.3) (1.1.2)\n",
            "Requirement already satisfied: aiosignal in /usr/local/lib/python3.12/dist-packages (from ray==2.40.0->ray[adag]==2.40.0->vllm==0.7.3) (1.4.0)\n",
            "Requirement already satisfied: frozenlist in /usr/local/lib/python3.12/dist-packages (from ray==2.40.0->ray[adag]==2.40.0->vllm==0.7.3) (1.8.0)\n",
            "Requirement already satisfied: cupy-cuda12x in /usr/local/lib/python3.12/dist-packages (from ray[adag]==2.40.0->vllm==0.7.3) (13.3.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.0->bitsandbytes==0.45.3) (3.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.0->bitsandbytes==0.45.3) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch<3,>=2.0->bitsandbytes==0.45.3)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch<3,>=2.0->bitsandbytes==0.45.3)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch<3,>=2.0->bitsandbytes==0.45.3)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch<3,>=2.0->bitsandbytes==0.45.3)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch<3,>=2.0->bitsandbytes==0.45.3)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch<3,>=2.0->bitsandbytes==0.45.3)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch<3,>=2.0->bitsandbytes==0.45.3)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch<3,>=2.0->bitsandbytes==0.45.3)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch<3,>=2.0->bitsandbytes==0.45.3)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.21.5 (from torch<3,>=2.0->bitsandbytes==0.45.3)\n",
            "  Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.4.127 (from torch<3,>=2.0->bitsandbytes==0.45.3)\n",
            "  Downloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch<3,>=2.0->bitsandbytes==0.45.3)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting triton==3.1.0 (from torch<3,>=2.0->bitsandbytes==0.45.3)\n",
            "  Downloading triton-3.1.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\n",
            "Collecting sympy==1.13.1 (from torch<3,>=2.0->bitsandbytes==0.45.3)\n",
            "  Downloading sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting pybind11 (from xgrammar==0.1.11->vllm==0.7.3)\n",
            "  Downloading pybind11-3.0.1-py3-none-any.whl.metadata (10.0 kB)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.12/dist-packages (from xgrammar==0.1.11->vllm==0.7.3) (8.4.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy==1.13.1->torch<3,>=2.0->bitsandbytes==0.45.3) (1.3.0)\n",
            "Requirement already satisfied: starlette<0.49.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from fastapi!=0.113.*,!=0.114.0,>=0.107.0->fastapi[standard]!=0.113.*,!=0.114.0,>=0.107.0; python_version >= \"3.9\"->vllm==0.7.3) (0.48.0)\n",
            "Collecting fastapi-cli>=0.0.8 (from fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]!=0.113.*,!=0.114.0,>=0.107.0; python_version >= \"3.9\"->vllm==0.7.3)\n",
            "  Downloading fastapi_cli-0.0.13-py3-none-any.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: httpx<1.0.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from fastapi[standard]!=0.113.*,!=0.114.0,>=0.107.0; python_version >= \"3.9\"->vllm==0.7.3) (0.28.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.12/dist-packages (from fastapi[standard]!=0.113.*,!=0.114.0,>=0.107.0; python_version >= \"3.9\"->vllm==0.7.3) (0.0.20)\n",
            "Collecting email-validator>=2.0.0 (from fastapi[standard]!=0.113.*,!=0.114.0,>=0.107.0; python_version >= \"3.9\"->vllm==0.7.3)\n",
            "  Downloading email_validator-2.3.0-py3-none-any.whl.metadata (26 kB)\n",
            "Requirement already satisfied: uvicorn>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]!=0.113.*,!=0.114.0,>=0.107.0; python_version >= \"3.9\"->vllm==0.7.3) (0.37.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers==4.48.2) (1.1.10)\n",
            "Collecting pydantic-extra-types>=2.10.5 (from pydantic-extra-types[pycountry]>=2.10.5->mistral_common>=1.5.0->mistral_common[opencv]>=1.5.0->vllm==0.7.3)\n",
            "  Downloading pydantic_extra_types-2.10.6-py3-none-any.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: opencv-python-headless>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from mistral_common[opencv]>=1.5.0->vllm==0.7.3) (4.12.0.88)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai>=1.52.0->vllm==0.7.3) (4.11.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai>=1.52.0->vllm==0.7.3) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai>=1.52.0->vllm==0.7.3) (0.11.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai>=1.52.0->vllm==0.7.3) (1.3.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.9->vllm==0.7.3) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.9->vllm==0.7.3) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.9->vllm==0.7.3) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->vllm==0.7.3) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->vllm==0.7.3) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->vllm==0.7.3) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->vllm==0.7.3) (2025.10.5)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->vllm==0.7.3) (2.6.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->vllm==0.7.3) (25.4.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->vllm==0.7.3) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->vllm==0.7.3) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->vllm==0.7.3) (1.22.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib_metadata->vllm==0.7.3) (3.23.0)\n",
            "Collecting dnspython>=2.0.0 (from email-validator>=2.0.0->fastapi[standard]!=0.113.*,!=0.114.0,>=0.107.0; python_version >= \"3.9\"->vllm==0.7.3)\n",
            "  Downloading dnspython-2.8.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: typer>=0.15.1 in /usr/local/lib/python3.12/dist-packages (from fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]!=0.113.*,!=0.114.0,>=0.107.0; python_version >= \"3.9\"->vllm==0.7.3) (0.19.2)\n",
            "Collecting rich-toolkit>=0.14.8 (from fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]!=0.113.*,!=0.114.0,>=0.107.0; python_version >= \"3.9\"->vllm==0.7.3)\n",
            "  Downloading rich_toolkit-0.15.1-py3-none-any.whl.metadata (1.0 kB)\n",
            "Collecting fastapi-cloud-cli>=0.1.1 (from fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]!=0.113.*,!=0.114.0,>=0.107.0; python_version >= \"3.9\"->vllm==0.7.3)\n",
            "  Downloading fastapi_cloud_cli-0.3.1-py3-none-any.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0,>=0.23.0->fastapi[standard]!=0.113.*,!=0.114.0,>=0.107.0; python_version >= \"3.9\"->vllm==0.7.3) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0,>=0.23.0->fastapi[standard]!=0.113.*,!=0.114.0,>=0.107.0; python_version >= \"3.9\"->vllm==0.7.3) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->outlines==0.1.11->vllm==0.7.3) (3.0.3)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema->outlines==0.1.11->vllm==0.7.3) (2025.9.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema->outlines==0.1.11->vllm==0.7.3) (0.27.1)\n",
            "INFO: pip is looking at multiple versions of opencv-python-headless to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting opencv-python-headless>=4.0.0 (from mistral_common[opencv]>=1.5.0->vllm==0.7.3)\n",
            "  Downloading opencv_python_headless-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]!=0.113.*,!=0.114.0,>=0.107.0; python_version >= \"3.9\"->vllm==0.7.3)\n",
            "  Downloading httptools-0.7.1-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]!=0.113.*,!=0.114.0,>=0.107.0; python_version >= \"3.9\"->vllm==0.7.3) (1.1.1)\n",
            "Collecting uvloop>=0.15.1 (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]!=0.113.*,!=0.114.0,>=0.107.0; python_version >= \"3.9\"->vllm==0.7.3)\n",
            "  Downloading uvloop-0.21.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]!=0.113.*,!=0.114.0,>=0.107.0; python_version >= \"3.9\"->vllm==0.7.3)\n",
            "  Downloading watchfiles-1.1.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]!=0.113.*,!=0.114.0,>=0.107.0; python_version >= \"3.9\"->vllm==0.7.3) (15.0.1)\n",
            "Requirement already satisfied: fastrlock>=0.5 in /usr/local/lib/python3.12/dist-packages (from cupy-cuda12x->ray[adag]==2.40.0->vllm==0.7.3) (0.8.3)\n",
            "Requirement already satisfied: iniconfig>=1 in /usr/local/lib/python3.12/dist-packages (from pytest->xgrammar==0.1.11->vllm==0.7.3) (2.1.0)\n",
            "Requirement already satisfied: pluggy<2,>=1.5 in /usr/local/lib/python3.12/dist-packages (from pytest->xgrammar==0.1.11->vllm==0.7.3) (1.6.0)\n",
            "Requirement already satisfied: pygments>=2.7.2 in /usr/local/lib/python3.12/dist-packages (from pytest->xgrammar==0.1.11->vllm==0.7.3) (2.19.2)\n",
            "Collecting rignore>=0.5.1 (from fastapi-cloud-cli>=0.1.1->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]!=0.113.*,!=0.114.0,>=0.107.0; python_version >= \"3.9\"->vllm==0.7.3)\n",
            "  Downloading rignore-0.7.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: sentry-sdk>=2.20.0 in /usr/local/lib/python3.12/dist-packages (from fastapi-cloud-cli>=0.1.1->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]!=0.113.*,!=0.114.0,>=0.107.0; python_version >= \"3.9\"->vllm==0.7.3) (2.40.0)\n",
            "Requirement already satisfied: rich>=13.7.1 in /usr/local/lib/python3.12/dist-packages (from rich-toolkit>=0.14.8->fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]!=0.113.*,!=0.114.0,>=0.107.0; python_version >= \"3.9\"->vllm==0.7.3) (13.9.4)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.15.1->fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]!=0.113.*,!=0.114.0,>=0.107.0; python_version >= \"3.9\"->vllm==0.7.3) (1.5.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=13.7.1->rich-toolkit>=0.14.8->fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]!=0.113.*,!=0.114.0,>=0.107.0; python_version >= \"3.9\"->vllm==0.7.3) (4.0.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=13.7.1->rich-toolkit>=0.14.8->fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]!=0.113.*,!=0.114.0,>=0.107.0; python_version >= \"3.9\"->vllm==0.7.3) (0.1.2)\n",
            "Downloading bitsandbytes-0.45.3-py3-none-manylinux_2_24_x86_64.whl (76.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.1/76.1 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading vllm-0.7.3-cp38-abi3-manylinux1_x86_64.whl (264.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.6/264.6 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading transformers-4.48.2-py3-none-any.whl (9.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m88.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading compressed_tensors-0.9.1-py3-none-any.whl (96 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.5/96.5 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading depyf-0.18.0-py3-none-any.whl (38 kB)\n",
            "Downloading gguf-0.10.0-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.6/71.6 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lark-1.2.2-py3-none-any.whl (111 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.0/111.0 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading outlines-0.1.11-py3-none-any.whl (87 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.6/87.6 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ray-2.40.0-cp312-cp312-manylinux2014_x86_64.whl (67.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch-2.5.1-cp312-cp312-manylinux1_x86_64.whl (906.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m906.4/906.4 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchaudio-2.5.1-cp312-cp312-manylinux1_x86_64.whl (3.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m79.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchvision-0.20.1-cp312-cp312-manylinux1_x86_64.whl (7.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m92.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xformers-0.0.28.post3-cp312-cp312-manylinux_2_28_x86_64.whl (16.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.7/16.7 MB\u001b[0m \u001b[31m57.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xgrammar-0.1.11-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (396 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m396.4/396.4 kB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m125.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m97.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m67.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m87.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading outlines_core-0.1.26-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (343 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m343.2/343.2 kB\u001b[0m \u001b[31m33.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m116.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-3.1.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.6/209.6 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lm_format_enforcer-0.10.12-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mistral_common-1.8.5-py3-none-any.whl (6.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m124.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m115.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading prometheus_fastapi_instrumentator-7.1.0-py3-none-any.whl (19 kB)\n",
            "Downloading tokenizers-0.21.4-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m111.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading blake3-1.0.7-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (387 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m387.9/387.9 kB\u001b[0m \u001b[31m37.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading msgspec-0.19.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (213 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m213.6/213.6 kB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading partial_json_parser-0.2.1.1.post6-py3-none-any.whl (10 kB)\n",
            "Downloading email_validator-2.3.0-py3-none-any.whl (35 kB)\n",
            "Downloading fastapi_cli-0.0.13-py3-none-any.whl (11 kB)\n",
            "Downloading interegular-0.3.3-py37-none-any.whl (23 kB)\n",
            "Downloading opencv_python_headless-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (50.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.0/50.0 MB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_extra_types-2.10.6-py3-none-any.whl (40 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pycountry-24.6.1-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m137.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading airportsdata-20250909-py3-none-any.whl (914 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m914.4/914.4 kB\u001b[0m \u001b[31m70.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading astor-0.8.1-py2.py3-none-any.whl (27 kB)\n",
            "Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pybind11-3.0.1-py3-none-any.whl (293 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m293.6/293.6 kB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dnspython-2.8.0-py3-none-any.whl (331 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m331.1/331.1 kB\u001b[0m \u001b[31m33.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fastapi_cloud_cli-0.3.1-py3-none-any.whl (19 kB)\n",
            "Downloading httptools-0.7.1-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (517 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m517.7/517.7 kB\u001b[0m \u001b[31m43.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rich_toolkit-0.15.1-py3-none-any.whl (29 kB)\n",
            "Downloading uvloop-0.21.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m131.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchfiles-1.1.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (452 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m452.2/452.2 kB\u001b[0m \u001b[31m38.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rignore-0.7.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (951 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m951.1/951.1 kB\u001b[0m \u001b[31m54.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: uvloop, triton, sympy, rignore, pycountry, pybind11, partial-json-parser, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, msgspec, lark, interegular, httptools, dnspython, diskcache, blake3, astor, airportsdata, watchfiles, opencv-python-headless, nvidia-cusparse-cu12, nvidia-cudnn-cu12, gguf, email-validator, depyf, tokenizers, rich-toolkit, pydantic-extra-types, prometheus-fastapi-instrumentator, nvidia-cusolver-cu12, lm-format-enforcer, transformers, torch, ray, outlines_core, fastapi-cloud-cli, fastapi-cli, xgrammar, xformers, torchvision, torchaudio, outlines, mistral_common, compressed-tensors, bitsandbytes, vllm\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.4.0\n",
            "    Uninstalling triton-3.4.0:\n",
            "      Successfully uninstalled triton-3.4.0\n",
            "  Attempting uninstall: sympy\n",
            "    Found existing installation: sympy 1.13.3\n",
            "    Uninstalling sympy-1.13.3:\n",
            "      Successfully uninstalled sympy-1.13.3\n",
            "  Attempting uninstall: nvidia-nvtx-cu12\n",
            "    Found existing installation: nvidia-nvtx-cu12 12.6.77\n",
            "    Uninstalling nvidia-nvtx-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-nvtx-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.6.85\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.6.85:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.6.85\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.27.3\n",
            "    Uninstalling nvidia-nccl-cu12-2.27.3:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.27.3\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.7.77\n",
            "    Uninstalling nvidia-curand-cu12-10.3.7.77:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.7.77\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.3.0.4\n",
            "    Uninstalling nvidia-cufft-cu12-11.3.0.4:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.3.0.4\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.6.77\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.6.77\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.6.80\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.6.80:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.6.80\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.6.4.1\n",
            "    Uninstalling nvidia-cublas-cu12-12.6.4.1:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.6.4.1\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: lark\n",
            "    Found existing installation: lark 1.3.0\n",
            "    Uninstalling lark-1.3.0:\n",
            "      Successfully uninstalled lark-1.3.0\n",
            "  Attempting uninstall: opencv-python-headless\n",
            "    Found existing installation: opencv-python-headless 4.12.0.88\n",
            "    Uninstalling opencv-python-headless-4.12.0.88:\n",
            "      Successfully uninstalled opencv-python-headless-4.12.0.88\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.4.2\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.4.2:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.4.2\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.10.2.21\n",
            "    Uninstalling nvidia-cudnn-cu12-9.10.2.21:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.10.2.21\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.22.1\n",
            "    Uninstalling tokenizers-0.22.1:\n",
            "      Successfully uninstalled tokenizers-0.22.1\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.7.1.2\n",
            "    Uninstalling nvidia-cusolver-cu12-11.7.1.2:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.7.1.2\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.57.0\n",
            "    Uninstalling transformers-4.57.0:\n",
            "      Successfully uninstalled transformers-4.57.0\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.8.0+cu126\n",
            "    Uninstalling torch-2.8.0+cu126:\n",
            "      Successfully uninstalled torch-2.8.0+cu126\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.23.0+cu126\n",
            "    Uninstalling torchvision-0.23.0+cu126:\n",
            "      Successfully uninstalled torchvision-0.23.0+cu126\n",
            "  Attempting uninstall: torchaudio\n",
            "    Found existing installation: torchaudio 2.8.0+cu126\n",
            "    Uninstalling torchaudio-2.8.0+cu126:\n",
            "      Successfully uninstalled torchaudio-2.8.0+cu126\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed airportsdata-20250909 astor-0.8.1 bitsandbytes-0.45.3 blake3-1.0.7 compressed-tensors-0.9.1 depyf-0.18.0 diskcache-5.6.3 dnspython-2.8.0 email-validator-2.3.0 fastapi-cli-0.0.13 fastapi-cloud-cli-0.3.1 gguf-0.10.0 httptools-0.7.1 interegular-0.3.3 lark-1.2.2 lm-format-enforcer-0.10.12 mistral_common-1.8.5 msgspec-0.19.0 numpy-1.26.4 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 opencv-python-headless-4.11.0.86 outlines-0.1.11 outlines_core-0.1.26 partial-json-parser-0.2.1.1.post6 prometheus-fastapi-instrumentator-7.1.0 pybind11-3.0.1 pycountry-24.6.1 pydantic-extra-types-2.10.6 ray-2.40.0 rich-toolkit-0.15.1 rignore-0.7.0 sympy-1.13.1 tokenizers-0.21.4 torch-2.5.1 torchaudio-2.5.1 torchvision-0.20.1 transformers-4.48.2 triton-3.1.0 uvloop-0.21.0 vllm-0.7.3 watchfiles-1.1.0 xformers-0.0.28.post3 xgrammar-0.1.11\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "950b978779bf4540bfea983c85af3b67"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 한글 처리를 위한 matplotlib 설정 (1)\n",
        "\n",
        "!sudo apt-get install -y fonts-nanum\n",
        "!sudo fc-cache –fv\n",
        "!rm ~/.cache/matplotlib -rf"
      ],
      "metadata": {
        "id": "2PyUVMjnwv4n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d31d66b-4099-4e4e-8a12-c4c4d59a0bc0"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  fonts-nanum\n",
            "0 upgraded, 1 newly installed, 0 to remove and 38 not upgraded.\n",
            "Need to get 10.3 MB of archives.\n",
            "After this operation, 34.1 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 fonts-nanum all 20200506-1 [10.3 MB]\n",
            "Fetched 10.3 MB in 2s (5,124 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package fonts-nanum.\n",
            "(Reading database ... 126675 files and directories currently installed.)\n",
            "Preparing to unpack .../fonts-nanum_20200506-1_all.deb ...\n",
            "Unpacking fonts-nanum (20200506-1) ...\n",
            "Setting up fonts-nanum (20200506-1) ...\n",
            "Processing triggers for fontconfig (2.13.1-4.2ubuntu5) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 런타임 -> 세션 다시 시작"
      ],
      "metadata": {
        "id": "xjT6NMJ_wxoM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 한글 처리를 위한 matplotlib 설정 (2)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.rc('font', family='NanumBarunGothic')"
      ],
      "metadata": {
        "id": "1Q-jeRwcwzly"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. 데이터 수집 및 전처리"
      ],
      "metadata": {
        "id": "Evptw6-lw2j-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 14-1 RSS 피드에서 이미지 URL 추출"
      ],
      "metadata": {
        "id": "GyE957VBw3Nt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "fjrPWcd1AFKx"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from lxml import etree\n",
        "from lxml.html import fromstring\n",
        "import pandas as pd\n",
        "\n",
        "def extract_unique_images(rss_url):\n",
        "    ## 주어진 RSS 피드 URL에서 고유한 이미지 URL들을 추출하는 함수 정의\n",
        "    try:\n",
        "        ## requests 라이브러리를 사용하여 RSS 피드 URL로부터 내용을 가져옴\n",
        "        response = requests.get(rss_url)\n",
        "        ## 가져온 XML 응답 내용을 lxml의 etree.fromstring으로 파싱하여 XML 트리 root를 생성\n",
        "        root = etree.fromstring(response.content)\n",
        "        image_urls = set()\n",
        "\n",
        "        ## XML 트리에서 모든 'item' 태그를 XPath를 사용하여 순회\n",
        "        for item in root.xpath('//item'):\n",
        "            description = item.find('description')\n",
        "            if description is not None and description.text:\n",
        "                ## description의 텍스트 내용을 lxml.html.fromstring으로 파싱하여 HTML 트리를 생성\n",
        "                html_tree = fromstring(description.text)\n",
        "                ## HTML 트리에서 첫 번째 <img> 태그의 'src' 속성 값을 XPath를 사용하여 추출\n",
        "                img_url = html_tree.xpath('string(//img/@src)')\n",
        "                if img_url:\n",
        "                    image_urls.add(img_url)\n",
        "\n",
        "        return list(image_urls)\n",
        "\n",
        "    except Exception as e:\n",
        "        ## 오류 발생 시 오류 메시지를 출력하고 빈 리스트를 반환\n",
        "        print(f\"Error occurred: {e}\")\n",
        "        return []\n",
        "\n",
        "rss_url = \"https://glltn.com/feed/\"\n",
        "## extract_unique_images 함수를 호출하여 고유한 이미지 URL들을 추출\n",
        "unique_images = extract_unique_images(rss_url)\n",
        "\n",
        "## 추출된 이미지 URL 리스트를 사용하여 'image'라는 열을 가진 pandas DataFrame을 생성\n",
        "df = pd.DataFrame(unique_images, columns=[\"image\"])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "id": "n6a8VBjH9L7l",
        "outputId": "586bbd80-7dfc-4d39-afed-9d67c79c2152"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                image\n",
              "0   https://glltn.com/wp-content/blogs.dir/1/files...\n",
              "1   https://glltn.com/wp-content/blogs.dir/1/files...\n",
              "2   https://glltn.com/wp-content/blogs.dir/1/files...\n",
              "3   https://glltn.com/wp-content/blogs.dir/1/files...\n",
              "4   https://glltn.com/wp-content/blogs.dir/1/files...\n",
              "5   https://glltn.com/wp-content/blogs.dir/1/files...\n",
              "6   https://glltn.com/wp-content/blogs.dir/1/files...\n",
              "7   https://glltn.com/wp-content/blogs.dir/1/files...\n",
              "8   https://glltn.com/wp-content/blogs.dir/1/files...\n",
              "9   https://glltn.com/wp-content/blogs.dir/1/files...\n",
              "10  https://glltn.com/wp-content/blogs.dir/1/files...\n",
              "11  https://glltn.com/wp-content/blogs.dir/1/files..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cb2a79b6-2739-463e-87f5-4b0e753878ed\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>https://glltn.com/wp-content/blogs.dir/1/files...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>https://glltn.com/wp-content/blogs.dir/1/files...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>https://glltn.com/wp-content/blogs.dir/1/files...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>https://glltn.com/wp-content/blogs.dir/1/files...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>https://glltn.com/wp-content/blogs.dir/1/files...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>https://glltn.com/wp-content/blogs.dir/1/files...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>https://glltn.com/wp-content/blogs.dir/1/files...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>https://glltn.com/wp-content/blogs.dir/1/files...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>https://glltn.com/wp-content/blogs.dir/1/files...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>https://glltn.com/wp-content/blogs.dir/1/files...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>https://glltn.com/wp-content/blogs.dir/1/files...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>https://glltn.com/wp-content/blogs.dir/1/files...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cb2a79b6-2739-463e-87f5-4b0e753878ed')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-cb2a79b6-2739-463e-87f5-4b0e753878ed button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-cb2a79b6-2739-463e-87f5-4b0e753878ed');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-42f05f44-dd2b-4084-b260-43e7d93df3f0\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-42f05f44-dd2b-4084-b260-43e7d93df3f0')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-42f05f44-dd2b-4084-b260-43e7d93df3f0 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_14d422ff-f00e-4386-8ca4-29225ad7e523\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_14d422ff-f00e-4386-8ca4-29225ad7e523 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 12,\n  \"fields\": [\n    {\n      \"column\": \"image\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 12,\n        \"samples\": [\n          \"https://glltn.com/wp-content/blogs.dir/1/files/2025/09/tone-fall-winter-2025-collection-lookbook-08-1024x683.jpg\",\n          \"https://glltn.com/wp-content/blogs.dir/1/files/2025/09/joel-meyerowitz-a-sense-of-wonder-book-01-1024x683.jpg\",\n          \"https://glltn.com/wp-content/blogs.dir/1/files/2025/09/bluebluejapan-fall-winter-2025-collection-lookbook-11-1024x683.jpg\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 14-2 수집 데이터 확인"
      ],
      "metadata": {
        "id": "XT6FFqgn42yK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, HTML\n",
        "\n",
        "def path_to_image_html(path):\n",
        "    ## 이미지 경로를 HTML img 태그로 변환하는 함수\n",
        "    return f'<img src=\"{path}\" width=\"300\" />'\n",
        "\n",
        "## DataFrame의 스타일을 설정하여 이미지 너비를 300px로 지정\n",
        "df.style.set_table_styles([{'selector': 'img', 'props': 'width: 300px;'}])\n",
        "\n",
        "## DataFrame을 HTML로 변환하여 출력. 이미지 열은 path_to_image_html 함수로 포맷팅\n",
        "display(HTML(df.to_html(escape=False, formatters=dict(**{'image': path_to_image_html}))))"
      ],
      "metadata": {
        "id": "DVMvyxJOAOo1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8a585e34-31a1-4709-f65c-50065b2137d3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td><img src=\"https://glltn.com/wp-content/blogs.dir/1/files/2025/09/bluebluejapan-fall-winter-2025-collection-lookbook-11-1024x683.jpg\" width=\"300\" /></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td><img src=\"https://glltn.com/wp-content/blogs.dir/1/files/2025/10/kelen-fall-winter-2025-collection-lookbook-22-1024x683.jpg\" width=\"300\" /></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td><img src=\"https://glltn.com/wp-content/blogs.dir/1/files/2025/10/rakines-fall-winter-2025-collection-lookbook-08-1024x682.jpg\" width=\"300\" /></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td><img src=\"https://glltn.com/wp-content/blogs.dir/1/files/2025/09/minotaur-fall-winter-2025-collection-lookbook-38-1024x683.jpg\" width=\"300\" /></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td><img src=\"https://glltn.com/wp-content/blogs.dir/1/files/2025/09/trove-spring-summer-2026-collection-lookbook-10-1024x683.jpg\" width=\"300\" /></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td><img src=\"https://glltn.com/wp-content/blogs.dir/1/files/2025/09/eel-products-fall-winter-2025-collection-lookbook-13-1024x683.jpg\" width=\"300\" /></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td><img src=\"https://glltn.com/wp-content/blogs.dir/1/files/2025/09/south2-west8-suicoke-fall-winter-2025-beetle-lo-01-1024x683.jpg\" width=\"300\" /></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td><img src=\"https://glltn.com/wp-content/blogs.dir/1/files/2025/09/daido-moriyama-quartet-book-01-1024x683.jpg\" width=\"300\" /></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td><img src=\"https://glltn.com/wp-content/blogs.dir/1/files/2025/09/ulterior-fall-winter-2025-collection-lookbook-08-1024x683.jpg\" width=\"300\" /></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td><img src=\"https://glltn.com/wp-content/blogs.dir/1/files/2025/09/joel-meyerowitz-a-sense-of-wonder-book-01-1024x683.jpg\" width=\"300\" /></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td><img src=\"https://glltn.com/wp-content/blogs.dir/1/files/2025/09/tone-fall-winter-2025-collection-lookbook-08-1024x683.jpg\" width=\"300\" /></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td><img src=\"https://glltn.com/wp-content/blogs.dir/1/files/2025/09/sage-de-cret-2-fall-winter-2025-collection-lookbook-15-1024x683.jpg\" width=\"300\" /></td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. VLM을 이용한 이미지 분석"
      ],
      "metadata": {
        "id": "X8tIpX9A3oMV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 14-3 VLM 모델 로드"
      ],
      "metadata": {
        "id": "wKQ3p2-alzLF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from PIL import Image\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "\n",
        "## 'openbmb/MiniCPM-V-2_6-int4' 모델을 사전 훈련된 가중치와 함께 로드\n",
        "## trust_remote_code=True는 허브에서 사용자 정의 코드를 실행할 수 있도록 허용\n",
        "model = AutoModel.from_pretrained('openbmb/MiniCPM-V-2_6-int4', trust_remote_code=True)\n",
        "## 로드된 모델에 해당하는 토크나이저를 로드\n",
        "tokenizer = AutoTokenizer.from_pretrained('openbmb/MiniCPM-V-2_6-int4', trust_remote_code=True)\n",
        "## 모델을 평가 모드로 설정 (드롭아웃 등 훈련 시에만 필요한 기능 비활성화)\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "c1IXBK01ASWj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "![](https://farm3.staticflickr.com/2677/4434956914_6e95a22940_z.jpg)"
      ],
      "metadata": {
        "id": "xrr3p8fslk4v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 14-4 이미지 질문 응답 예시"
      ],
      "metadata": {
        "id": "58PxIp8SmUl3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import set_seed\n",
        "\n",
        "## 재현성을 위해 시드(seed)를 42로 설정\n",
        "set_seed(42)\n",
        "## 예시 이미지 URL 정의\n",
        "image_url = 'https://farm3.staticflickr.com/2677/4434956914_6e95a22940_z.jpg'\n",
        "## requests로 이미지 다운로드 후 PIL Image 객체로 열고 RGB 형식으로 변환\n",
        "image = Image.open(requests.get(image_url, stream=True).raw).convert('RGB')\n",
        "## 이미지에 대한 질문 정의\n",
        "question = 'how many cats in the photo?'\n",
        "## 모델 입력 형식에 맞춰 메시지 구성 (이미지와 질문 포함)\n",
        "msgs = [{'role': 'user', 'content': [image, question]}]\n",
        "## 모델의 chat 함수를 호출하여 이미지와 질문에 대한 응답 생성\n",
        "result = model.chat(image=None, msgs=msgs, tokenizer=tokenizer)\n",
        "## 모델의 응답 출력\n",
        "print(result)"
      ],
      "metadata": {
        "id": "OLk-R6PYATVS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "set_seed(86)\n",
        "## 이미지에 대한 질문을 업데이트. 책 표지의 고양이도 포함하도록 요청\n",
        "question = 'how many cats in the photo? including the books cover.'\n",
        "## 모델 입력 형식에 맞춰 메시지 구성 (이전에 로드된 이미지와 업데이트된 질문 포함)\n",
        "msgs = [{'role': 'user', 'content': [image, question]}]\n",
        "## 모델의 chat 함수를 호출하여 업데이트된 질문에 대한 응답 생성\n",
        "result = model.chat(image=None, msgs=msgs, tokenizer=tokenizer)\n",
        "## 모델의 응답 출력\n",
        "print(result)"
      ],
      "metadata": {
        "id": "B1KelJIrAU2J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e140bf8-160f-47e1-cb5e-083f721090e4"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "set_seed(42)\n",
        "## 이미지에 대한 질문을 'describe the photo'로 설정하여 이미지 내용을 설명하도록 요청\n",
        "question = 'describe the photo'\n",
        "## 모델 입력 형식에 맞춰 메시지 구성 (이전에 로드된 이미지와 설명 요청 질문 포함)\n",
        "msgs = [{'role': 'user', 'content': [image, question]}]\n",
        "## 모델의 chat 함수를 호출하여 이미지에 대한 설명을 생성\n",
        "result = model.chat(image=None, msgs=msgs, tokenizer=tokenizer)\n",
        "## 모델의 응답 (이미지 설명) 출력\n",
        "print(result)"
      ],
      "metadata": {
        "id": "UCd9smsCAWH6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8c4732b-17f4-421f-c82a-b67cf2aac066"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The photo shows a book with the title \"why dogs are better than cats\" and an image of a cat sitting on top of a dog's head. The book is placed on a flat surface, and next to it stands a real cat that appears to be looking at the book cover with some curiosity or disapproval.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 14-5 의류 이미지 여부 판단"
      ],
      "metadata": {
        "id": "Hyv4G27NnxxH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def is_picture_of_clothing(image_url):\n",
        "    ## 이미지 URL이 의류 사진인지 판단하는 함수\n",
        "    # 의류가 포함된 사진인지 확인하는 질문 작성 (영어로)\n",
        "    question = 'Is this a picture of clothing? MUST say yes or no.'\n",
        "    image = Image.open(requests.get(image_url, stream=True).raw).convert('RGB')\n",
        "    msgs = [{'role': 'user', 'content': [image, question]}]\n",
        "    result = model.chat(image=None, msgs=msgs, tokenizer=tokenizer, temperature=0.1)\n",
        "    print(result)\n",
        "    ## 응답에 'yes'가 포함되어 있는지 확인하여 True/False 반환\n",
        "    return 'yes' in result.lower()\n",
        "\n",
        "## DataFrame의 'image' 열에 함수를 적용하여 'is_clothing' 열에 결과 저장\n",
        "df['is_clothing'] = df['image'].apply(is_picture_of_clothing)"
      ],
      "metadata": {
        "id": "KnJ0trHgAXTq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e86d3525-8a79-4cc8-86c4-6e56af453436"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Yes, this image is of clothing. It appears to be a fashion photograph showcasing the individual's outfit, which includes a black blazer and tie-dye trousers. The focus on the attire suggests that it may be used for promotional or retail purposes, highlighting the style and design elements of the garments.\n",
            "Yes.\n",
            "Yes, this image appears to be a picture of clothing. The focus is on the attire worn by the individual, specifically highlighting the shirt and jeans as key elements of the outfit. The style and fit of the clothing are presented in a manner that suggests it could be used for fashion or retail purposes, where the aim is to showcase the garments themselves rather than the person wearing them.\n",
            "Yes, this image is of clothing. It appears to be a fashion shoot showcasing winter outerwear, specifically parkas or coats designed for cold weather. The focus on the garments and the models' poses suggest that the purpose of the photograph is to display these items of clothing in a way that highlights their design and functionality.\n",
            "Yes.\n",
            "Yes, this image appears to be a picture of clothing. The focus is on the individual's attire, specifically highlighting the design and fit of the shirt and trousers. The photograph seems to serve as a showcase for these garments, possibly for fashion purposes such as a catalog or a lookbook.\n",
            "Yes, this image is of clothing. Specifically, it is a pair of hiking shoes designed for outdoor activities. The presence of laces, the sturdy construction, and the tread pattern on the sole are characteristic features that identify these items as footwear rather than other types of clothing or accessories.\n",
            "No, the image does not appear to be of clothing. It is an artistic representation that seems to focus on a close-up of a face with a green tint, which could suggest it's either a piece of art or a stylized photograph rather than a depiction of wearable items.\n",
            "Yes, this image is of clothing. It specifically showcases a piece of apparel that the individual in the photograph is wearing. The focus on the garment and its details, such as the buttons and neckline, indicates that it is meant to be viewed as an example or advertisement for the clothing item.\n",
            "No, the image is not of clothing. It is a book cover featuring a photograph by Joel Meyerowitz titled \"A Sense of Wonder Fotografie 1962-2022.\" The content on the cover suggests that it is related to photography and likely contains images or works from the specified time period.\n",
            "Yes, this image is of clothing. The focus is on the knitwear worn by the individual, which includes a textured sweater and a beanie with distinctive stripes. These items are clearly visible and serve as the main subjects of the photograph, indicating that the picture is indeed centered around clothing.\n",
            "Yes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 14-6 의류 판단 결과 시각화"
      ],
      "metadata": {
        "id": "l4l7QsLaoCoQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "display(HTML(df.to_html(escape=False, formatters=dict(**{'image': path_to_image_html}))))"
      ],
      "metadata": {
        "id": "rOtwke1pAd8J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 14-7 의류 이미지 필터링"
      ],
      "metadata": {
        "id": "0aSaNQ7eoUWS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## 'is_clothing' 열의 값이 True인 행들만 필터링하여 DataFrame을 업데이트\n",
        "df = df[df['is_clothing']]\n",
        "display(HTML(df.to_html(escape=False, formatters=dict(**{'image': path_to_image_html}))))\n"
      ],
      "metadata": {
        "id": "X3prbhccAfdo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 14-8 의류 스타일 분석"
      ],
      "metadata": {
        "id": "UMo5LkOzoaEc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def describe_style(image_url):\n",
        "    ## 주어진 이미지 URL의 의류 스타일을 분석하는 함수\n",
        "    question = 'Analyze the style of the clothes. Please let me explain the colors and trend changes.'\n",
        "    image = Image.open(requests.get(image_url, stream=True).raw).convert('RGB')\n",
        "    msgs = [{'role': 'user', 'content': [image, question]}]\n",
        "    ## 모델의 chat 함수를 호출하여 이미지에 대한 스타일 분석 응답 생성\n",
        "    result = model.chat(image=None, msgs=msgs, tokenizer=tokenizer)\n",
        "    return result\n",
        "\n",
        "## 필터링된 DataFrame의 'image' 열에 describe_style 함수를 적용\n",
        "## 결과는 'style'이라는 새로운 열에 저장\n",
        "df['style'] = df['image'].apply(describe_style)"
      ],
      "metadata": {
        "id": "FxgObQ1ZAgVY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6cb7e892-38b2-4fb3-bad5-4efcc1a4c18a"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1874085826.py:12: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['style'] = df['image'].apply(describe_style)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "display(HTML(df.to_html(escape=False, formatters=dict(**{'image': path_to_image_html}))))"
      ],
      "metadata": {
        "id": "i-znn3Z0qjJb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4af23bcc-c6d9-4e24-bf6b-eb545a960be1"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image</th>\n",
              "      <th>is_clothing</th>\n",
              "      <th>style</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td><img src=\"https://glltn.com/wp-content/blogs.dir/1/files/2025/09/bluebluejapan-fall-winter-2025-collection-lookbook-11-1024x683.jpg\" width=\"300\" /></td>\n",
              "      <td>True</td>\n",
              "      <td>The style of the clothes in the image suggests a blend of classic and contemporary fashion trends. The black blazer with its mandarin collar is reminiscent of traditional menswear, often associated with formality and sophistication. However, the modern twist comes from the casual fit of the blazer and the presence of large buttons that add an edgy detail to the otherwise conservative piece.\\n\\nThe white turtleneck shirt underneath adds a layer of depth to the outfit, providing both warmth and a contrast against the dark blazer. It's a timeless choice that can be seen in various fashion eras, indicating a nod to classic styles.\\n\\nThe tie-dye pants introduce a bold, artistic element to the ensemble. Tie-dye has been a recurring trend in fashion, often symbolizing creativity and non-conformity. This particular pair, with its deep blue hues, stands out as a statement piece, suggesting a fusion of streetwear influences with more formal elements like the blazer.\\n\\nOverall, the combination of these items reflects a transitional look that could appeal to those who appreciate a mix of old and new aesthetics, bridging the gap between traditional men's wear and modern street-style trends.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td><img src=\"https://glltn.com/wp-content/blogs.dir/1/files/2025/10/kelen-fall-winter-2025-collection-lookbook-22-1024x683.jpg\" width=\"300\" /></td>\n",
              "      <td>True</td>\n",
              "      <td>The sweater worn by the man in the image exhibits a style that is often associated with traditional or folk-inspired knitwear. The use of earthy tones such as beige, dark brown, and shades of green suggests a preference for natural colors which are commonly seen in casual or outdoor clothing. The pattern on the sweater includes geometric shapes and motifs that could be indicative of cultural heritage or regional design trends.\\n\\nIn terms of trend changes, this type of sweater can be considered somewhat timeless due to its classic color palette and simple yet intricate patterns. However, it may not follow the more recent fashion trends that favor minimalism, monochromatic palettes, or highly graphic prints. Instead, this garment seems to lean towards comfort and functionality, possibly appealing to those who prefer a more understated and possibly vintage-inspired look.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td><img src=\"https://glltn.com/wp-content/blogs.dir/1/files/2025/10/rakines-fall-winter-2025-collection-lookbook-08-1024x682.jpg\" width=\"300\" /></td>\n",
              "      <td>True</td>\n",
              "      <td>The style of the clothes in the image reflects a casual and slightly vintage-inspired aesthetic. The off-white, long-sleeve button-up shirt is reminiscent of classic workwear or possibly a vintage piece that has been modernized for contemporary wear. Such shirts are often associated with comfort and versatility, making them suitable for various occasions from casual outings to more relaxed business settings.\\n\\nThe color choice of pale yellow adds a soft, summery feel to the outfit, suggesting it might be part of a spring or summer collection. This hue is not only trendy but also evokes a sense of freshness and simplicity. Paired with light blue denim shorts, which have a faded wash giving them a worn-in look, the ensemble strikes a balance between laid-back and stylish.\\n\\nIn terms of trend changes, this combination of a loose-fitting, unbuttoned shirt with denim shorts is a nod to streetwear influences, where comfort and ease of movement are key. The relaxed fit and neutral colors suggest an effortless style, popular in recent fashion trends that favor minimalism and timeless pieces over fast-fashion items. Overall, the attire presented is indicative of a current fashion preference for comfortable yet fashionable clothing that can transition easily between different seasons.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td><img src=\"https://glltn.com/wp-content/blogs.dir/1/files/2025/09/minotaur-fall-winter-2025-collection-lookbook-38-1024x683.jpg\" width=\"300\" /></td>\n",
              "      <td>True</td>\n",
              "      <td>The style of the clothes in the image suggests a contemporary, utilitarian fashion trend that emphasizes comfort and functionality. The olive green coats are practical for cold weather, with their high hoods and large pockets, which indicate a design focus on warmth and storage. This color choice is often associated with military or outdoor gear, suggesting a nod to rugged, versatile clothing suitable for various environments.\\n\\nThe grey hoodies underneath add a layer of casualness and ease to the overall look, blending seamlessly with the muted tones of the outerwear. Grey is a neutral color that complements a wide range of hues, making it a popular choice for layering pieces. The combination of these garments reflects a modern approach to winter fashion where comfort and style intersect, catering to those who value both aesthetics and utility in their wardrobe choices.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td><img src=\"https://glltn.com/wp-content/blogs.dir/1/files/2025/09/trove-spring-summer-2026-collection-lookbook-10-1024x683.jpg\" width=\"300\" /></td>\n",
              "      <td>True</td>\n",
              "      <td>The style of the clothes worn by the individual in the photograph can be described as minimalist and utilitarian. The dark colors, such as black or navy, are often associated with a classic and timeless look that is versatile for various occasions. This color choice also tends to give off a sophisticated and understated vibe.\\n\\nMinimalist fashion typically avoids excessive ornamentation and focuses on clean lines, simple shapes, and functional design. The rolled-up sleeves suggest a casual yet thoughtful approach to dressing, indicating an attention to detail without being overly formal. The belted waist adds a practical element to the outfit, providing both aesthetic interest and functionality.\\n\\nIn terms of trend changes, minimalist styles have been popular for several years due to their simplicity and elegance. They offer a modern take on traditional clothing items, making them suitable for contemporary wardrobes. The combination of a blazer-like top with more relaxed pants suggests a blend of formality and comfort, which is a common trend in current fashion circles where versatility and ease of movement are highly valued.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td><img src=\"https://glltn.com/wp-content/blogs.dir/1/files/2025/09/eel-products-fall-winter-2025-collection-lookbook-13-1024x683.jpg\" width=\"300\" /></td>\n",
              "      <td>True</td>\n",
              "      <td>The style of the clothes in the image suggests a contemporary fashion sense with an emphasis on simplicity and comfort. The dark green shirt has a classic design, likely made from a sturdy fabric suitable for casual wear or possibly workwear, given its robust appearance. The burgundy collar peeking under the shirt adds a subtle pop of color, which is a common trend in layering to create visual interest without overwhelming the overall look.\\n\\nThe patterned pants are particularly noteworthy as they introduce texture and pattern into an otherwise solid-colored outfit. This choice indicates a blend of traditional and modern styles, where patterns have been making a resurgence in men's fashion, often seen in both casual and smart-casual settings.\\n\\nOverall, the ensemble reflects a transitional style that could be versatile enough for various occasions, blending functionality with a touch of personal flair through color coordination and pattern selection.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td><img src=\"https://glltn.com/wp-content/blogs.dir/1/files/2025/09/south2-west8-suicoke-fall-winter-2025-beetle-lo-01-1024x683.jpg\" width=\"300\" /></td>\n",
              "      <td>True</td>\n",
              "      <td>The shoes in the image exhibit a style that is practical and utilitarian, often associated with outdoor activities such as hiking or trekking. The color palette of earthy tones—specifically shades of brown—is indicative of a design that aims to blend with natural environments, which is a common trend in outdoor gear. This choice of color not only serves a functional purpose but also aligns with current fashion trends that favor natural, muted colors over bright, bold hues.\\n\\nIn terms of trend changes, there has been a noticeable shift towards more sustainable and eco-friendly practices in the fashion industry, which includes the use of materials that are both durable and environmentally conscious. The suede-like material suggests an effort to provide comfort while potentially using less water-intensive production processes compared to genuine leather. Additionally, the sturdy construction and reinforced areas like the toe box and heel counter indicate a focus on durability and longevity, appealing to consumers who prioritize quality and sustainability in their purchases.\\n\\nOverall, these shoes reflect a contemporary trend where functionality meets environmental consciousness, catering to a market segment that values both performance and ethical considerations in their clothing choices.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td><img src=\"https://glltn.com/wp-content/blogs.dir/1/files/2025/09/ulterior-fall-winter-2025-collection-lookbook-08-1024x683.jpg\" width=\"300\" /></td>\n",
              "      <td>True</td>\n",
              "      <td>The style of the clothes worn by the individual in the image leans towards a minimalist and monochromatic aesthetic. The black color is often associated with simplicity, elegance, and versatility, making it a popular choice for casual wear as well as fashion statements. The Henley shirt is a classic piece that has seen a resurgence in popularity due to its timeless design and comfort. It combines elements of both streetwear and smart-casual styles, which aligns with contemporary fashion trends that favor ease of movement and understated elegance.\\n\\nThe long sleeves and relaxed fit suggest an emphasis on comfort and possibly an influence from urban or hipster fashion, where oversized garments are favored for their laid-back look. This trend has been prevalent in recent years, especially among younger demographics who prioritize comfort without sacrificing style.\\n\\nOverall, the outfit reflects a modern, effortless chic that is both stylish and functional, catering to those who prefer a no-nonsense approach to dressing while still maintaining a sense of personal expression through their clothing choices.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td><img src=\"https://glltn.com/wp-content/blogs.dir/1/files/2025/09/tone-fall-winter-2025-collection-lookbook-08-1024x683.jpg\" width=\"300\" /></td>\n",
              "      <td>True</td>\n",
              "      <td>The clothing style in the image leans towards a casual, possibly streetwear aesthetic. The knit sweater is a classic piece that has seen numerous fashion trends over the years but remains timeless due to its versatility and comfort. The choice of a dark grey color for the sweater suggests a preference for neutral tones, which are often favored for their ability to pair well with various other colors and styles.\\n\\nThe beanie's ribbed texture and the contrasting yellow stripes add a subtle touch of pattern and color without being overly bold or distracting. This kind of accessory can serve both a functional purpose—providing warmth—and a stylistic one, contributing to an overall look that is both practical and fashionable.\\n\\nIn terms of trend changes, the combination of a high-necked sweater and a beanie could suggest an influence from winter fashion trends where layering and headwear are essential for warmth but also serve as statement pieces. The simplicity of the outfit indicates a preference for understated elegance, which has been a recurring theme in fashion, especially during cooler seasons when more fabric is worn.\\n\\nOverall, the clothes reflect a modern, perhaps urban style that balances functionality with contemporary fashion sensibilities.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td><img src=\"https://glltn.com/wp-content/blogs.dir/1/files/2025/09/sage-de-cret-2-fall-winter-2025-collection-lookbook-15-1024x683.jpg\" width=\"300\" /></td>\n",
              "      <td>True</td>\n",
              "      <td>The style of the clothes in the image leans towards a casual, utilitarian aesthetic with an emphasis on practicality and comfort. The olive green jacket is reminiscent of military or outdoor gear, which has seen a resurgence in popularity due to its functionality and versatility. This color choice is often associated with earthy tones that are trending for their ability to blend with natural environments and urban settings alike.\\n\\nUnderneath the jacket, there's a layering technique that adds depth and texture to the outfit. Layering is a common trend in fashion as it allows for adaptability to changing weather conditions while also providing a more dynamic visual interest. The light blue striped shirt underneath introduces a subtle pattern without being overly flashy, adhering to a minimalist yet stylish approach.\\n\\nThe dark pants complement the overall look by balancing out the lighter colors above. They provide a solid base that grounds the ensemble, preventing it from appearing too busy or overwhelming.\\n\\nOverall, the clothing style suggests a preference for timeless pieces that can be mixed and matched to create different looks, reflecting a contemporary take on classic styles.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. LLM을 이용한 키워드 분석 및 보고서 작성"
      ],
      "metadata": {
        "id": "0z6BhTZeopo6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 14-9 언어 모델(LLM) 로드"
      ],
      "metadata": {
        "id": "ebRE0K15oqr9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from vllm import LLM, SamplingParams\n",
        "\n",
        "## vLLM 라이브러리를 사용하여 'LGAI-EXAONE/EXAONE-3.5-2.4B-Instruct' 모델을 로드\n",
        "## gpu_memory_utilization은 GPU 메모리 사용 비율을 0.5로 설정\n",
        "## max_model_len은 모델이 처리할 수 있는 최대 토큰 길이를 10000으로 설정\n",
        "llm = LLM(model='LGAI-EXAONE/EXAONE-3.5-2.4B-Instruct', gpu_memory_utilization=0.5, max_model_len=10000)"
      ],
      "metadata": {
        "id": "hiQAZ-csAiI4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 14-10 색상 정보 추출"
      ],
      "metadata": {
        "id": "Sj470n8wo86w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from vllm import SamplingParams ## SamplingParams 임포트가 필요\n",
        "\n",
        "def extract_color(style):\n",
        "  ## 주어진 스타일 설명 텍스트에서 색상을 한글로 추출하는 함수\n",
        "  prompt = [\n",
        "      {\n",
        "          \"role\": \"system\",\n",
        "          \"content\": \"You are EXAONE model from LG AI Research, a helpful assistant.\"\n",
        "      },\n",
        "      {\n",
        "          \"role\": \"user\",\n",
        "          \"content\": f\"다음의 글에서 색상을 한글로 추출해 주세요. 색상 외의 다른 정보는 다른 정보는 적지 말아주세요.\\n{style}\" # vlm이 작성한 글에서 색상 정보 추출, 한글로 번역하면서\n",
        "      }\n",
        "  ]\n",
        "  ## 샘플링 파라미터 설정 (온도, top_p, 최대 토큰 수)\n",
        "  sampling_params = SamplingParams(temperature=0.2, top_p=0.95, max_tokens=1024)\n",
        "  ## LLM 모델을 사용하여 프롬프트에 대한 응답 생성\n",
        "  result = llm.chat(prompt, sampling_params)[0].outputs[0].text\n",
        "  print(result)\n",
        "  return result\n",
        "\n",
        "## DataFrame의 'style' 열에 extract_color 함수를 적용\n",
        "## 결과는 'color'라는 새로운 열에 저장\n",
        "df['color'] = df['style'].apply(extract_color)"
      ],
      "metadata": {
        "id": "ci7oHspgAjuw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 14-11 스타일 키워드 추출"
      ],
      "metadata": {
        "id": "hdHnIoYapBPr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from vllm import SamplingParams ## SamplingParams 임포트가 필요\n",
        "\n",
        "def extract_style(style):\n",
        "  ## 주어진 스타일 설명 텍스트에서 스타일 키워드를 한글로 추출하는 함수\n",
        "  prompt = [\n",
        "      {\n",
        "          \"role\": \"system\",\n",
        "          \"content\": \"You are EXAONE model from LG AI Research, a helpful assistant.\"\n",
        "      },\n",
        "      {\n",
        "          \"role\": \"user\",\n",
        "          \"content\": f\"다음의 글에서 스타일 캐워드를 한글로 추출해주세요. 스타일 키워드 외에 다른 정보는 적지 말아주세요.\" # vlm이 작성한 글에서 스타일 키워드 추출, 한글로 번역하면서\n",
        "      }\n",
        "  ]\n",
        "  ## 샘플링 파라미터 설정 (온도, top_p, 최대 토큰 수)\n",
        "  sampling_params = SamplingParams(temperature=0.2, top_p=0.95, max_tokens=1024)\n",
        "  ## LLM 모델을 사용하여 프롬프트에 대한 응답 생성\n",
        "  result = llm.chat(prompt, sampling_params)[0].outputs[0].text\n",
        "  print(result)\n",
        "  return result\n",
        "\n",
        "## DataFrame의 'style' 열에 extract_color 함수를 적용 (함수 이름은 이전과 동일하지만 기능 변경)\n",
        "## 결과는 'keyword'라는 새로운 열에 저장\n",
        "df['keyword'] = df['style'].apply(extract_style)"
      ],
      "metadata": {
        "id": "9CGzC0QlAlNo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(HTML(df.to_html(escape=False, formatters=dict(**{'image': path_to_image_html}))))"
      ],
      "metadata": {
        "id": "nxI64xM-qpRh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 14-12 텍스트 데이터 정제"
      ],
      "metadata": {
        "id": "sLXLdNUhpK8e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def clean_text(text):\n",
        "    ## 텍스트에서 특수 문자 및 HTML 태그를 제거하고 소문자로 변환하는 함수\n",
        "    if isinstance(text, str):\n",
        "       ## 영문, 숫자, 한글, 공백을 제외한 모든 문자 제거\n",
        "       text = re.sub(r'[^a-zA-Z0-9가-힣\\s]', '', text)\n",
        "       ## HTML 태그 제거\n",
        "       text = re.sub(r'<[^>]*>', '', text)\n",
        "       ## 텍스트를 소문자로 변환\n",
        "       text = text.lower()\n",
        "       return text\n",
        "    else:\n",
        "        return \"\"\n",
        "\n",
        "## 'color' 열의 텍스트 데이터 정제\n",
        "df['color'] = df['color'].apply(clean_text)\n",
        "## 'keyword' 열의 텍스트 데이터 정제\n",
        "df['keyword'] = df['keyword'].apply(clean_text)"
      ],
      "metadata": {
        "id": "nAhvdWHVAm0g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 14-13 워드 클라우드 생성 및 시각화"
      ],
      "metadata": {
        "id": "CNg6DakapO_k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "from wordcloud import WordCloud\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def get_word_count(df):\n",
        "    ## DataFrame의 'color'와 'keyword' 열에서 단어 빈도를 계산하는 함수\n",
        "    if not df.empty:\n",
        "        ## 'color' 열의 모든 단어를 리스트로 합침\n",
        "        all_nouns = df['color'].apply(str.split).sum()\n",
        "        ## 'keyword' 열의 모든 단어를 추가\n",
        "        all_nouns += df['keyword'].apply(str.split).sum()\n",
        "        ## '색상' 단어를 제외한 모든 단어를 필터링\n",
        "        all_nouns = [word for word in all_nouns if word not in ['색상']]\n",
        "        ## 단어 빈도를 Counter 객체로 반환\n",
        "        return Counter(all_nouns)\n",
        "    return Counter() ## DataFrame이 비어있으면 빈 Counter 반환\n",
        "\n",
        "def create_wordcloud(word_count):\n",
        "    ## 단어 빈도수를 기반으로 워드 클라우드를 생성하고 시각화하는 함수\n",
        "    if not word_count: ## 단어 빈도가 없으면 워드클라우드 생성하지 않음\n",
        "        print(\"No words to generate word cloud.\")\n",
        "        return\n",
        "\n",
        "    wordcloud = WordCloud(\n",
        "        width=800,\n",
        "        height=400,\n",
        "        background_color='white',\n",
        "        colormap='viridis',\n",
        "        font_path='/usr/share/fonts/truetype/nanum/NanumBarunGothic.ttf' ## 한글 폰트 경로 지정\n",
        "        ).generate_from_frequencies(word_count)\n",
        "\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.imshow(wordcloud, interpolation='bilinear')\n",
        "    plt.axis(\"off\") ## 축 표시 제거\n",
        "    plt.show() ## 워드 클라우드 출력\n",
        "\n",
        "## DataFrame에서 단어 빈도 계산\n",
        "word_count = get_word_count(df)\n",
        "## 계산된 단어 빈도로 워드 클라우드 생성 및 시각화\n",
        "create_wordcloud(word_count)"
      ],
      "metadata": {
        "id": "newpDQHoAoGG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 14-14 트렌드 분석 보고서 생성 프롬프트 구성 및 실행"
      ],
      "metadata": {
        "id": "eDO_o8uop2M_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 14-15 분석 보고서 시각화"
      ],
      "metadata": {
        "id": "m304vCZMp7ov"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from vllm import SamplingParams ## SamplingParams 임포트가 필요\n",
        "\n",
        "## 시스템 메시지로 시작하는 프롬프트 리스트 초기화\n",
        "prompt = [\n",
        "    {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": \"You are EXAONE model from LG AI Research, a helpful assistant.\"\n",
        "    }\n",
        "]\n",
        "## DataFrame의 각 행을 순회하며 '스타일 노트'와 '이미지 URL'을 사용자 메시지로 추가\n",
        "for row in df.itertuples():\n",
        "  prompt.append({\"role\": \"user\", \"content\": f\"스타일 노트: {row.style}\\n이미지 url:{row.image}\"})\n",
        "## 마지막으로, 종합적인 트렌드 분석 보고서 작성을 요청하는 사용자 메시지 추가\n",
        "## 보고서 제목, 내용의 전문성, 마크다운 형식, 예시 이미지 포함을 지시\n",
        "prompt.append({\"role\": \"user\", \"content\": \"주어진 스타일 노트를 토대로 종합적인 트랜드 방향의 분석 보고서를 작성해주세요. 보고서의 제목은 해외 룩북 스타일 분석입니다. 내용은 전문적이면서 명확하게 작성해주세요. 문서 형식은 markdown 형식으로 만들어주세요.\"})\n",
        "\n",
        "## 샘플링 파라미터 설정 (온도, top_p, 최대 토큰 수)\n",
        "sampling_params = SamplingParams(temperature=0.2, top_p=0.95, max_tokens=4096)\n",
        "## LLM 모델을 사용하여 구성된 프롬프트에 대한 응답 생성\n",
        "result = llm.chat(prompt, sampling_params)[0].outputs[0].text"
      ],
      "metadata": {
        "id": "x6LZ3FCtApst"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, Markdown\n",
        "\n",
        "## LLM으로부터 생성된 결과(Markdown 형식의 보고서)를 Jupyter 환경에 표시\n",
        "display(Markdown(result))"
      ],
      "metadata": {
        "id": "7C7KDpS6Aq7w"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}